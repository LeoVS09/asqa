{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39ae4d6",
   "metadata": {},
   "source": [
    "# Pack Search Models\n",
    "\n",
    "Pack NN, tokenaizers, index, passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9863c8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotly standard imports\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "\n",
    "# Cufflinks wrapper on plotly\n",
    "import cufflinks\n",
    "\n",
    "# Data science imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Set global theme\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2518e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVE_FOLDER = './search_data'\n",
    "PASSAGES_FILENAME = f'{ARCHIVE_FOLDER}/passages'\n",
    "INDEX_FILENAME = f'{ARCHIVE_FOLDER}/index'\n",
    "TOKENIZER_FILENAME = f'{ARCHIVE_FOLDER}/tokenizer'\n",
    "MODEL_FILENAME = f'{ARCHIVE_FOLDER}/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc7a4e",
   "metadata": {},
   "source": [
    "## Save search passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9ce4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wiki_snippets (./datasets/wiki_snippets/wiki40b_en_100_0/1.0.0/d152a0e6a420c02b9b26e7f75f45fb54c818cae1d83e8f164f0b1a13ac7998ae)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "wiki40b_passages = load_dataset('wiki_snippets', name='wiki40b_en_100_0', cache_dir='./datasets')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8d5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki40b_passages.save_to_disk(PASSAGES_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9878a",
   "metadata": {},
   "source": [
    "### Check passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bbdc1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '{\"datasets_id\": 0, \"wiki_id\": \"Q1294448\", \"sp\": 2, \"sc\": 0, \"ep\": 6, \"ec\": 610}',\n",
       " 'datasets_id': 0,\n",
       " 'wiki_id': 'Q1294448',\n",
       " 'start_paragraph': 2,\n",
       " 'start_character': 0,\n",
       " 'end_paragraph': 6,\n",
       " 'end_character': 610,\n",
       " 'article_title': 'Ági Szalóki',\n",
       " 'section_title': 'Life',\n",
       " 'passage_text': \"Ági Szalóki Life She started singing as a toddler, considering Márta Sebestyén a role model. Her musical background is traditional folk music; she first won recognition for singing with Ökrös in a traditional folk style, and Besh o droM, a Balkan gypsy brass band. With these ensembles she toured around the world from the Montreal Jazz Festival, through Glastonbury Festival to the Théatre de la Ville in Paris, from New York to Beijing.\\nSince 2005, she began to pursue her solo career and explore various genres, such as jazz, thirties ballads, or children's songs.\\nUntil now, three of her six released albums\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "passages = Dataset.load_from_disk(PASSAGES_FILENAME)\n",
    "\n",
    "passages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf93e200",
   "metadata": {},
   "source": [
    "## Save index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09fbcf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./search_data/index'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('./wiki40b_passages_reps_32_l-8_h-768_b-512-512.dat', INDEX_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811e731",
   "metadata": {},
   "source": [
    "### Check index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec49abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "wiki40b_passage_reps = np.memmap(\n",
    "    INDEX_FILENAME,\n",
    "    dtype='float32', mode='r',\n",
    "    shape=(wiki40b_passages.num_rows, 128)\n",
    ")\n",
    "\n",
    "wiki40b_index_flat = faiss.IndexFlatIP(128)\n",
    "\n",
    "wiki40b_index_flat.add(wiki40b_passage_reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa1267",
   "metadata": {},
   "source": [
    "## Save model and tokenaizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286e41a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RetriBertModel were not initialized from the model checkpoint at yjernite/retribert-base-uncased and are newly initialized: ['bert_query.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "qar_tokenizer = AutoTokenizer.from_pretrained('yjernite/retribert-base-uncased', cache_dir='./tokenaizers')\n",
    "qar_model = AutoModel.from_pretrained('yjernite/retribert-base-uncased', cache_dir='./models')\n",
    "_ = qar_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e376eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./search_data/tokenizer/tokenizer_config.json',\n",
       " './search_data/tokenizer/special_tokens_map.json',\n",
       " './search_data/tokenizer/vocab.txt',\n",
       " './search_data/tokenizer/added_tokens.json',\n",
       " './search_data/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qar_tokenizer.save_pretrained(TOKENIZER_FILENAME)\n",
    "qar_model.save_pretrained(MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f2304",
   "metadata": {},
   "source": [
    "### Check model and tokenaizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7cea3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qar_tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_FILENAME, use_fast=False)\n",
    "qar_model = AutoModel.from_pretrained(MODEL_FILENAME)\n",
    "_ = qar_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2384f2c",
   "metadata": {},
   "source": [
    "## Pack and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b518e16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model packed to /work/search_data.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "def pack_folder(source_dir = '', file_name = ''):\n",
    "    \n",
    "    with tarfile.open(file_name + '.tar.gz', 'w:gz') as f:\n",
    "        f.add(source_dir, arcname = os.path.basename(source_dir))\n",
    "    \n",
    "    return f\"{os.getcwd()}/{file_name}.tar.gz\"\n",
    "\n",
    "model_filename = pack_folder(ARCHIVE_FOLDER, 'search_data')\n",
    "print('model packed to', model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7473ee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b91bfb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "\n",
    "def upload_file(model_path='', s3_bucket='', s3_filename=''):\n",
    "    s3 = boto3.session.Session()\n",
    "    client = s3.client('s3')\n",
    "    return client.upload_file(model_path, s3_bucket, s3_filename)\n",
    "    \n",
    "upload_file(model_filename, 'asqa-search-models', 'DPR/en.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b05eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
