{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a8a7dc0",
   "metadata": {},
   "source": [
    "# Pack AnsweringModels\n",
    "\n",
    "Pack NN, tokenaizers, index, passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac7c162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotly standard imports\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "\n",
    "# Cufflinks wrapper on plotly\n",
    "import cufflinks\n",
    "\n",
    "# Data science imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Set global theme\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f75f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVE_FOLDER = './answer_data'\n",
    "TOKENIZER_FILENAME = f'{ARCHIVE_FOLDER}/tokenizer'\n",
    "MODEL_FILENAME = f'{ARCHIVE_FOLDER}/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7851785a",
   "metadata": {},
   "source": [
    "## Save model and tokenaizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e37106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "qa_s2s_tokenizer = AutoTokenizer.from_pretrained('yjernite/bart_eli5', cache_dir='./tokenaizers')\n",
    "qa_s2s_model = AutoModelForSeq2SeqLM.from_pretrained('yjernite/bart_eli5', cache_dir='./models')\n",
    "_ = qa_s2s_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20a849a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./answer_data/tokenizer/tokenizer_config.json',\n",
       " './answer_data/tokenizer/special_tokens_map.json',\n",
       " './answer_data/tokenizer/vocab.json',\n",
       " './answer_data/tokenizer/merges.txt',\n",
       " './answer_data/tokenizer/added_tokens.json',\n",
       " './answer_data/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_s2s_tokenizer.save_pretrained(TOKENIZER_FILENAME)\n",
    "qa_s2s_model.save_pretrained(MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b27542",
   "metadata": {},
   "source": [
    "### Check model and tokenaizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa137d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_s2s_tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_FILENAME, use_fast=False)\n",
    "qa_s2s_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_FILENAME)\n",
    "_ = qa_s2s_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e949798",
   "metadata": {},
   "source": [
    "## Pack and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e2660e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model packed to /work/search_data.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "def pack_folder(source_dir = '', file_name = ''):\n",
    "    \n",
    "    with tarfile.open(file_name + '.tar.gz', 'w:gz') as f:\n",
    "        f.add(source_dir, arcname = os.path.basename(source_dir))\n",
    "    \n",
    "    return f\"{os.getcwd()}/{file_name}.tar.gz\"\n",
    "\n",
    "model_filename = pack_folder(ARCHIVE_FOLDER, 'search_data')\n",
    "print('model packed to', model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0adfaa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "966a8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "\n",
    "def upload_file(model_path='', s3_bucket='', s3_filename=''):\n",
    "    s3 = boto3.session.Session()\n",
    "    client = s3.client('s3')\n",
    "    return client.upload_file(model_path, s3_bucket, s3_filename)\n",
    "    \n",
    "upload_file(model_filename, 'asqa-answer-models', 'BART/en.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7948b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
